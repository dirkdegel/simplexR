---
title: "Simplex Algorithm"
---

## Introduction

The simplex algorithm, developed by George Dantzig in 1947, solves LP problems by constructing a feasible solution at a vertex of the polytope and then walking along a path on the edges of the polytope to vertices with non-decreasing values of the objective function until an optimum is reached for sure. In many practical problems, "stalling" occurs: many pivots are made with no increase in the objective function. In rare practical problems, the usual versions of the simplex algorithm may actually "cycle". To avoid cycles, researchers developed new pivoting rules. In practice, the simplex algorithm is quite efficient and can be guaranteed to find the global optimum if certain precautions against cycling are taken. The simplex algorithm has been proved to solve "random" problems efficiently, i.e. in a cubic number of steps, which is similar to its behavior on practical problems. However, the simplex algorithm has poor worst-case behavior: Klee and Minty constructed a family of linear programming problems for which the simplex method takes a number of steps exponential in the problem size. In fact, for some time it was not known whether the linear programming problem was solvable in polynomial time, i.e. of complexity class $\mathbb{P}$.

### Basic Solutions â€“ Definition

Let $\mathcal{B}$ be an ordered set of $m$ distinct indices $(i_1,\ldots,i_m)$ taken from $\{1,\ldots,n\}$. $\mathcal{B}$ is called a basis for $\max\{ c^\intercal x \mid Ax = b, x \geq 0 \}$ if $A_B := A_{:j \in \mathcal{B}}$ is nonsingular. The variables $x_{B}$ are known as the basic variables and the variables $x_{N}$ as the non-basic variables, where $\mathcal{N} = (j_1,\ldots,j_{n-m}) = \{1,\ldots,n\}\backslash \mathcal{B}$. The corresponding basic solution $x \in \mathbb{R}^n$ is given by $x_{N} = 0$ and $x_{B} = A_B^{-1}b$. $\mathcal{B}$ is called (primal) *feasible* if $A_B^{-1}b \geq 0$ and $x$ is than called *basic feasible solution* (BFS).

Than the linear program in standard form
$$
z^\star = \max\{ c^\intercal x \mid Ax = b, x \geq 0 \}  
$$
can be written as:
$$
\begin{array}{ccc}
z^\star = \max & c_N^T x_N & + & c_B^T x_B \\
& A_N x_N & + & A_B x_B & = & b \\
& & & x_N,x_B & \geq & 0
\end{array}
$$
or alternatively (with the additional decision variable $z \in \mathbb{R}$) as:
$$
\begin{array}{rccc}
z^\star = \max \,\, z \\
z & - & c_N^T x_N & -  & c_B^T x_B & = & 0\\
&& A_N x_N & + & A_B x_B & = & b \\
&& & &x_N,x_B & \geq & 0
\end{array}
$$
Representation in 
$$x_B = A_B^{-1}b - A_B^{-1} A_N x_N$$

and
$$
\begin{array}{rrl}
z & = & c_N^T x_N + c_B^T x_B \\
  & = & c_N^T x_N + c_B^T \left[ A_B^{-1}b - A_B^{-1} A_N x_N \right] \\
  & = & c_N^T x_N + c_B^T  A_B^{-1}b - c_B^T A_B^{-1} A_N x_N \\
  & = & \left[ c_N^T - c_B^T A_B^{-1} A_N \right] x_N + c_B^TA_B^{-1} b
\end{array}
$$
and so
$$
\begin{array}{rccc}
z^\star = \max \left[ c_N^T - c_B^T A_B^{-1} A_N \right] x_N + c_B^TA_B^{-1} b \\
A_B^{-1}b - A_B^{-1} A_N x_N & \geq & 0 \\
x_N & \geq & 0
\end{array}
$$

### Theorem: Optimality Test

A basic (primal) feasible solution $x_B = A_B^{-1}b, x_N = 0$ is optimal, if $c_N^T - c_B^T A_B^{-1} A_N \geq 0$. The optimal objective value is $z^\star = c_B^TA_B^{-1} b$.

### Tableau Form  

$$
T_{\mathcal{B}} := 
\left[
\begin{array}{c|c}
-c^T + c_B^T A_B^{-1}A & c_B^T A_B^{-1} b \\
A_B^{-1}A & A_B^{-1}b 
\end{array}
\right]_{\mathcal{B}}
=
\left[
\begin{array}{cc|c}
-c_N^T + c_B^T A_B^{-1}A_N & - c_B^T + c_B^T A_B^{-1} A_B & c_B^T A_B^{-1} b \\
A_B^{-1}A_N  & A_B^{-1} A_B & A_B^{-1}b 
\end{array}
\right]_{\mathcal{B}}
$$

## Primal Simplex Algorithm (Tableau Form)

See Dantzig

Assume that a linear program is given in standard form:
$$
\begin{array}{ccc}
z^\star = \max & c_N^T x_N & + & 0 x_B \\
& A_N x_N & + & \mathbb{1} x_B & = & b \\
& & & x_N,x_B & \geq & 0
\end{array} 
\qquad\iff\qquad
\begin{array}{rccc}
z^\star = \max \,\, z \\
z & - & c_N^T x_N & -  & 0 x_B & = & 0\\
&& A_N x_N & + & \mathbb{1} x_B & = & b \\
&& & &z, x_N,x_B & \geq & 0
\end{array}
$$
where $A$ is of the form $A = (A_N, \mathbb{1})$. In the (primal) Simplex Algorithm it is *required* that the initial basic solution is (primal) feasible, i.e.,
$$
b\geq 0.
$$

The LP (initial basis $\mathcal{B} = (m+1,\ldots,n)$) is than written in tableau form (simplex tableau) as:
$$
T = \left[
\begin{array}{ccc|c}
1 & -c_N^T & 0 & 0 \\
0 & A_N  & \mathbb{1} & b 
\end{array}
\right]
=
\left[
\begin{array}{cc|c}
-c_N^T & 0 & 0 \\
A_N  & \mathbb{1} & b 
\end{array}
\right]
$$

Given a feasible basis $\mathcal{B}^{(k)}$ in iteration $k$ the current simplex tableau is:
$$
T^{(k)} = 
\left[
\begin{array}{cc|c}
-c_N^T + c_B^T A_B^{-1}A_N & -c_B^T + c_B^T A_B^{-1}\mathbb{1} & c_B^T A_B^{-1}b \\
A_B^{-1}A_N  & A_B^{-1}\mathbb{1} & A_B^{-1}b 
\end{array}
\right]^{(k)}_{\mathcal{B}}
=:_{sorted}
\bar{T} = 
\left[
\begin{array}{cc|c}
-\bar{c}_N^T & 0 & \bar{z} \\
\bar{A}_N  & \mathbb{1} & \bar{b} 
\end{array}
\right]_{\mathcal{B}^{(k)}}
$$

1. *Smallest Reduced Cost*: Determine
$$
j^{\star} = \arg\min_{j \in \mathcal{N}} \bar{c}_j
$$
where $j^{\star}$ is the index $j$ (argument) where $\bar{c_j}$ attains a minimum, that is, 
$$
\bar{c}_{j^{\star}} = \min_{j \in \mathcal{N}} \bar{c}_j
$$

2. *Optimality Test*: If $\bar{c}_{j^\star} \geq 0$, the basic feasible solution as optimal. Stop.

3. *Pivot Column* (Incoming Variable): If $\bar{c}_{j^\star} < 0$, then $j^\star$ is the index of the incoming basic variable.

4. *Test for unbounded* $c^T x$: If $\bar{A}_{j^\star} \leq 0$, the problem is unbounded $c^T x \to \infty$. Stop.

5. *Pivot Row* (Outgoing Variable) -- minimum ratio test.:
$$
i^{\star} = \arg\min_{i=1,\ldots,m} \left\{ \frac{\bar{b}_i}{\bar{a}_{i,j^\star}} \mid \bar{a}_{i,j^\star} > 0 \right\}
$$
In the case of ties ($i^{\star}$ is not unique), let $\mathcal{R}$ be the set of rows $k$ tied:
$$
\mathcal{R} = \left\{k \mid \frac{\bar{b}_k}{\bar{a}_{kj^\star}} \leq \frac{\bar{b}_i}{\bar{a}_{ij^\star}}, \bar{a}_{kj^\star} > 0,\bar{a}_{ij^\star} > 0, i = 1,\ldots, m \right\}
$$
- Primal nondeggenerated case: If $\bar{b}_k \geq 0$ for all $k \in \mathcal{R}$, choice of $k$ among the ties is arbitrary.

- Primal degenerated case: If $\bar{b}_k = 0$ for more than one $k \in \mathcal{R}$, Select the samllest index (Bland's rule).

6. *Pivot on* $\bar{a}_{i^\star j^\star}$:
- Pivot row $i^{\star}$: $\bar{T}_{i^{\star}:} \leftarrow \frac{\bar{T}_{i^{\star}:}}{\bar{a}_{i^\star j^\star}}$
- For $i = 1,\ldots,m; i \neq i^{\star}$: $\bar{T}_{i:} \leftarrow \bar{T}_{i:} - \bar{T}_{ij^\star} \cdot \bar{T}_{i^{\star}:}$
- old basis $\mathcal{B} = (i_1,\ldots,i_{i^\star-1},i_{i^\star},i_{i^\star+1},\ldots,i_m)$
- Basis: $\mathcal{B} \leftarrow (i_1,\ldots,i_{i^\star-1},j_{j^\star},i_{i^\star+1},\ldots,i_m)$
- Nonbasis: $\mathcal{N} \leftarrow (j_1,\ldots,j_{j^\star-1},i_{i^\star},j_{j^\star+1},\ldots,j_{n-m})$

### Example

See Werners 

Initial simplex tableau $T^{(0)}$: basis $\mathcal{B} = (3,4,5)$, $\mathcal{N} = (1,2)$, pivot column $j^\star = 1$, pivot row $i^\star = 3$.

$$
\begin{array}{rrrrrrr}
  \hline
 & x_{1} & x_{2} & s_{1} & s_{2} & s_{3} & \bar{b} \\ 
  \hline
  s_{1} & 2 & 1 & 1 & 0 & 0 & 22 \\ 
  s_{2} & 1 & 2 & 0 & 1 & 0 & 23 \\ 
  s_{3} & \mathbf{4} & 1 & 0 & 0 & 1 & 40 \\ 
  z & -3 & -2 & 0 & 0 & 0 & 0 \\ 
   \hline
\end{array}
$$

$$
\begin{array}{rcll}
\mathcal{N} & = & (\mathbf{1},2),   & j^\star = 1 & \mbox{variable $x_1$ at position $j^\star = 1$ in $\mathcal{N}$ enters the basis}\\
\mathcal{B} & = & (3,4,\mathbf{5}), & i^\star = 3 & \mbox{variable $s_3$ at position $i^\star = 3$ in $\mathcal{B}$ leaves the basis}
\end{array}
$$



$T^{(1)}$: basis $\mathcal{B} = (3,4,1)$, $\mathcal{N} = (5,2)$, pivot column $j^\star = 2$, pivot row $i^\star = 1$.

$$
\begin{array}{rrrrrrr}
  \hline
 & x_{1} & x_{2} & s_{1} & s_{2} & s_{3} & \bar{b} \\ 
  \hline
  s_{1} & 0 & \mathbf{0.5} & 1 & 0 & -0.5 & 2 \\ 
  s_{2} & 0 & 1.75 & 0 & 1 & -0.25 & 13 \\ 
  x_{1} & 1 & 0.25 & 0 & 0 & 0.25 & 10 \\ 
  z     & 0 &-1.25 & 0 & 0 & 0.75 & 30 \\ 
   \hline
\end{array}
$$

$$
\begin{array}{rcll}
\mathcal{N} & = & (\mathbf{1},2),   & j^\star = 1 & \mbox{variable $x_1$ at position $j^\star = 1$ in $\mathcal{N}$ enters the basis}\\
\mathcal{B} & = & (3,4,\mathbf{5}), & i^\star = 3 & \mbox{variable $s_3$ at position $i^\star = 3$ in $\mathcal{B}$ leaves the basis}
\end{array}
$$

$T^{(2)}$: basis $\mathcal{B} = (2,4,1)$, $\mathcal{N} = (5,3)$, pivot column $j^\star = 5$, pivot row $i^\star = 2$.

$$
\begin{array}{rrrrrrr}
  \hline
 & x_{1} & x_{2} & s_{1} & s_{2} & s_{3} & \bar{b} \\ 
  \hline
  x_{2} & 0 & 1 &  2   & 0 & -1   & 4 \\ 
  s_{2} & 0 & 0 & -3.5 & 1 &  \mathbf{1.5} & 6 \\ 
  x_{1} & 1 & 0 & -0.5 & 0 &  0.5 & 9 \\ 
  z     & 0 & 0 &  2.5 & 0 & -0.5 & 35 \\ 
   \hline
\end{array}
$$

$$
\begin{array}{rcll}
\mathcal{N} & = & (\mathbf{1},2),   & j^\star = 1 & \mbox{variable $x_1$ at position $j^\star = 1$ in $\mathcal{N}$ enters the basis}\\
\mathcal{B} & = & (3,4,\mathbf{5}), & i^\star = 3 & \mbox{variable $s_3$ at position $i^\star = 3$ in $\mathcal{B}$ leaves the basis}
\end{array}
$$

$T^{(3)}$: basis $\mathcal{B} = (2,5,1)$, $\mathcal{N} = (4,3)$. The basis is optimal.

$$
\begin{array}{rrrrrrr}
  \hline
 & x_{1} & x_{2} & s_{1} & s_{2} & s_{3} & \bar{b} \\ 
  \hline
  x_{2} & 0 & 1 & -0.33 &  0.67 & 0 &  8 \\ 
  s_{3} & 0 & 0 & -2.33 &  0.67 & 1 &  4 \\ 
  x_{1} & 1 & 0 &  0.67 & -0.33 & 0 &  7 \\ 
  z     & 0 & 0 &  1.33 &  0.33 & 0 & 37 \\ 
   \hline
\end{array}
$$


## BigM-Method

to do

## Two Phase Method

to do

## Rivised (primal) Simplex

to do

## Dual Simplex Algorithm

to do

